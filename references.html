<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>References | Modern Approaches in Natural Language Processing</title>
  <meta name="description" content="In this seminar, we are planning to review modern NLP frameworks starting with a methodology that can be seen as the beginning of modern NLP: Word Embeddings." />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="References | Modern Approaches in Natural Language Processing" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="In this seminar, we are planning to review modern NLP frameworks starting with a methodology that can be seen as the beginning of modern NLP: Word Embeddings." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="References | Modern Approaches in Natural Language Processing" />
  
  <meta name="twitter:description" content="In this seminar, we are planning to review modern NLP frameworks starting with a methodology that can be seen as the beginning of modern NLP: Word Embeddings." />
  

<meta name="author" content="" />


<meta name="date" content="2020-06-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="acknowledgements.html"/>

<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modern Approaches in Natural Language Processing</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="foreword.html"><a href="foreword.html"><i class="fa fa-check"></i>Foreword</a><ul>
<li class="chapter" data-level="" data-path="foreword.html"><a href="foreword.html#technical-setup"><i class="fa fa-check"></i>Technical Setup</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#intro-about-the-seminar-topic"><i class="fa fa-check"></i><b>1.1</b> Intro About the Seminar Topic</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#outline-of-the-booklet"><i class="fa fa-check"></i><b>1.2</b> Outline of the Booklet</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter-1.html"><a href="chapter-1.html"><i class="fa fa-check"></i><b>2</b> Chapter 1</a><ul>
<li class="chapter" data-level="2.1" data-path="chapter-1.html"><a href="chapter-1.html#lorem-ipsum"><i class="fa fa-check"></i><b>2.1</b> Lorem Ipsum</a></li>
<li class="chapter" data-level="2.2" data-path="chapter-1.html"><a href="chapter-1.html#using-figures"><i class="fa fa-check"></i><b>2.2</b> Using Figures</a></li>
<li class="chapter" data-level="2.3" data-path="chapter-1.html"><a href="chapter-1.html#using-tex"><i class="fa fa-check"></i><b>2.3</b> Using Tex</a></li>
<li class="chapter" data-level="2.4" data-path="chapter-1.html"><a href="chapter-1.html#using-stored-results"><i class="fa fa-check"></i><b>2.4</b> Using Stored Results</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction-deep-learning-for-nlp.html"><a href="introduction-deep-learning-for-nlp.html"><i class="fa fa-check"></i><b>3</b> Introduction: Deep Learning for NLP</a><ul>
<li class="chapter" data-level="3.1" data-path="introduction-deep-learning-for-nlp.html"><a href="introduction-deep-learning-for-nlp.html#word-embeddings-and-neural-network-language-models"><i class="fa fa-check"></i><b>3.1</b> Word Embeddings and Neural Network Language Models</a></li>
<li class="chapter" data-level="3.2" data-path="introduction-deep-learning-for-nlp.html"><a href="introduction-deep-learning-for-nlp.html#recurrent-neural-networks"><i class="fa fa-check"></i><b>3.2</b> Recurrent Neural Networks</a></li>
<li class="chapter" data-level="3.3" data-path="introduction-deep-learning-for-nlp.html"><a href="introduction-deep-learning-for-nlp.html#convolutional-neural-networks"><i class="fa fa-check"></i><b>3.3</b> Convolutional Neural Networks</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="foundationsapplications-of-modern-nlp.html"><a href="foundationsapplications-of-modern-nlp.html"><i class="fa fa-check"></i><b>4</b> Foundations/Applications of Modern NLP</a></li>
<li class="chapter" data-level="5" data-path="recurrent-neural-networks-and-their-applications-in-nlp.html"><a href="recurrent-neural-networks-and-their-applications-in-nlp.html"><i class="fa fa-check"></i><b>5</b> Recurrent neural networks and their applications in NLP</a><ul>
<li class="chapter" data-level="5.1" data-path="recurrent-neural-networks-and-their-applications-in-nlp.html"><a href="recurrent-neural-networks-and-their-applications-in-nlp.html#rnns"><i class="fa fa-check"></i><b>5.1</b> RNNs</a><ul>
<li class="chapter" data-level="5.1.1" data-path="recurrent-neural-networks-and-their-applications-in-nlp.html"><a href="recurrent-neural-networks-and-their-applications-in-nlp.html#structure"><i class="fa fa-check"></i><b>5.1.1</b> Structure</a></li>
<li class="chapter" data-level="5.1.2" data-path="recurrent-neural-networks-and-their-applications-in-nlp.html"><a href="recurrent-neural-networks-and-their-applications-in-nlp.html#backpropagation-and-drawbacks"><i class="fa fa-check"></i><b>5.1.2</b> Backpropagation and Drawbacks</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="recurrent-neural-networks-and-their-applications-in-nlp.html"><a href="recurrent-neural-networks-and-their-applications-in-nlp.html#gated-rnns"><i class="fa fa-check"></i><b>5.2</b> Gated RNNs</a><ul>
<li class="chapter" data-level="5.2.1" data-path="recurrent-neural-networks-and-their-applications-in-nlp.html"><a href="recurrent-neural-networks-and-their-applications-in-nlp.html#lstm"><i class="fa fa-check"></i><b>5.2.1</b> LSTM</a></li>
<li class="chapter" data-level="5.2.2" data-path="recurrent-neural-networks-and-their-applications-in-nlp.html"><a href="recurrent-neural-networks-and-their-applications-in-nlp.html#gru"><i class="fa fa-check"></i><b>5.2.2</b> GRU</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="recurrent-neural-networks-and-their-applications-in-nlp.html"><a href="recurrent-neural-networks-and-their-applications-in-nlp.html#versions"><i class="fa fa-check"></i><b>5.3</b> Versions</a><ul>
<li class="chapter" data-level="5.3.1" data-path="recurrent-neural-networks-and-their-applications-in-nlp.html"><a href="recurrent-neural-networks-and-their-applications-in-nlp.html#bidirectional-and-deep-rnns"><i class="fa fa-check"></i><b>5.3.1</b> Bidirectional and Deep RNNs</a></li>
<li class="chapter" data-level="5.3.2" data-path="recurrent-neural-networks-and-their-applications-in-nlp.html"><a href="recurrent-neural-networks-and-their-applications-in-nlp.html#applications"><i class="fa fa-check"></i><b>5.3.2</b> Applications</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="convolutional-neural-networks-and-their-applications-in-nlp.html"><a href="convolutional-neural-networks-and-their-applications-in-nlp.html"><i class="fa fa-check"></i><b>6</b> Convolutional neural networks and their applications in NLP</a></li>
<li class="chapter" data-level="7" data-path="introduction-transfer-learning-for-nlp.html"><a href="introduction-transfer-learning-for-nlp.html"><i class="fa fa-check"></i><b>7</b> Introduction: Transfer Learning for NLP</a></li>
<li class="chapter" data-level="8" data-path="transfer-learning-for-nlp-i.html"><a href="transfer-learning-for-nlp-i.html"><i class="fa fa-check"></i><b>8</b> Transfer Learning for NLP I</a></li>
<li class="chapter" data-level="9" data-path="attention-and-self-attention-for-nlp.html"><a href="attention-and-self-attention-for-nlp.html"><i class="fa fa-check"></i><b>9</b> Attention and Self-Attention for NLP</a></li>
<li class="chapter" data-level="10" data-path="transfer-learning-for-nlp-ii.html"><a href="transfer-learning-for-nlp-ii.html"><i class="fa fa-check"></i><b>10</b> Transfer Learning for NLP II</a></li>
<li class="chapter" data-level="11" data-path="introduction-resources-for-nlp.html"><a href="introduction-resources-for-nlp.html"><i class="fa fa-check"></i><b>11</b> Introduction: Resources for NLP</a></li>
<li class="chapter" data-level="12" data-path="resources-and-benchmarks-for-nlp.html"><a href="resources-and-benchmarks-for-nlp.html"><i class="fa fa-check"></i><b>12</b> Resources and Benchmarks for NLP</a></li>
<li class="chapter" data-level="13" data-path="software-for-nlp-the-huggingface-transformers-module.html"><a href="software-for-nlp-the-huggingface-transformers-module.html"><i class="fa fa-check"></i><b>13</b> Software for NLP: The huggingface transformers module</a></li>
<li class="chapter" data-level="14" data-path="use-bases-for-nlp.html"><a href="use-bases-for-nlp.html"><i class="fa fa-check"></i><b>14</b> Use-Bases for NLP</a></li>
<li class="chapter" data-level="15" data-path="use-case-i.html"><a href="use-case-i.html"><i class="fa fa-check"></i><b>15</b> Use-Case I</a></li>
<li class="chapter" data-level="16" data-path="use-case-ii.html"><a href="use-case-ii.html"><i class="fa fa-check"></i><b>16</b> Use-Case II</a></li>
<li class="chapter" data-level="17" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>17</b> Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modern Approaches in Natural Language Processing</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="references" class="section level1 unnumbered">
<h1>References</h1>

<div id="refs" class="references">
<div>
<p>Bengio, Yoshua, Réjean Ducharme, Pascal Vincent, and Christian Jauvin. 2003. “A Neural Probabilistic Language Model.” <em>Journal of Machine Learning Research</em>, no. 3: 1137–55.</p>
</div>
<div>
<p>Boden, Mikael. 2002. “A Guide to Recurrent Neural Networks and Backpropagation.” <em>The Dallas Project</em>.</p>
</div>
<div>
<p>Chollet, Francois. 2018. <em>Deep Learning Mit Python Und Keras: Das Praxis-Handbuch Vom Entwickler Der Keras-Bibliothek</em>. MITP-Verlags GmbH &amp; Co. KG.</p>
</div>
<div>
<p>Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep Learning</em>. MIT press.</p>
</div>
<div>
<p>Harris, Zellig S. 1954. “Distributional Structure.” <em>WORD</em> 10 (2-3): 146–62.</p>
</div>
<div>
<p>Kim, Yoon. 2014. <em>Convolutional Neural Networks for Sentence Classification</em>.</p>
</div>
<div>
<p>Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. 2012. <em>ImageNet Classification with Deep Convolutional Neural Networks</em>.</p>
</div>
<div>
<p>Mikolov, Tomas, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. “Distributed Representations of Words and Phrases and Their Compositionality.” <em>Advances in Neural Information Processing Systems</em>, 3111–9.</p>
</div>
<div>
<p>Pennington, Jeffrey, Richard Socher, Manning, and Christopher D. 2014. “GloVe: Global Vectors for Word Representation.” <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 1532–43.</p>
</div>
<div>
<p>R Core Team. 2018. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/" class="uri">https://www.R-project.org/</a>.</p>
</div>
<div>
<p>Schuster, Mike, and Kuldip K Paliwal. 1997. “Bidirectional Recurrent Neural Networks.” <em>IEEE Transactions on Signal Processing</em> 45 (11). Ieee: 2673–81.</p>
</div>
<div>
<p>Schwenk, Holger, Loïc Barrault, Alexis Conneau, and Yann LeCun. 2017. <em>Very Deep Convolutional Networks for Text Classification</em>.</p>
</div>
<div>
<p>Sutskever, Ilya, Oriol Vinyals, and Quoc V Le. 2014. “Sequence to Sequence Learning with Neural Networks.” In <em>Advances in Neural Information Processing Systems</em>, 3104–12.</p>
</div>
<div>
<p>Visin, Francesco, Kyle Kastner, Kyunghyun Cho, Matteo Matteucci, Aaron C. Courville, and Yoshua Bengio. 2015. <em>ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks</em>. <em>ArXiv</em>. Vol. abs/1505.00393.</p>
</div>
<div>
<p>Zhang, Xiang, Junbo Jake Zhao, and Yann LeCun. 2015. <em>Character-Level Convolutional Networks for Text Classification</em>.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="acknowledgements.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/compstat-lmu/seminar_nlp_ss20/edit/master/99-references.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book.pdf", "book.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
